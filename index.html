<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Haoning Wu</title>
  
  <meta name="author" content="Haoning Wu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml, <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üßê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Mengshun Hu „ÄåËÉ°Ê¢¶È°∫„Äç</name>
              </p>
              <p>I am currently a 2st-year PhD student of <a href="http://aim-nercms.whu.edu.cn/">AIM Lab</a> at <a href="https://www.whu.edu.cn/">Wuhan University (WHU)</a>, supervised by <a href="https://wangzwhu.github.io/home/">Prof. Zheng Wang</a>.
                My research interests are video frame interpolation (VFI), video super-resolution (VSR) and space-time video super-resolution (ST-VSR). I am also a visiting student supervised  by <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=JD-5DKcAAAAJ">Prof.Yinqiang Zheng</a> in <a href="https://www.u-tokyo.ac.jp/ja/index.html">University of Tokyo (UTokyo)</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:shunmh@whu.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=UlPRpmMAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/MengshunHu/">Github</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <heading>Preprints</heading>
          </td>
        </tr>
      </tbody></table>

       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/StoryGen.jpg" alt="storygen" width="160">
            </td>
            <td width="75%" valign="center">
              <a>
                <papertitle>NNVISR: Bring Neural Network Video Interpolation and Super Resolution into Video Processing Framework</papertitle>
              </a>
              <br>
              <a>Yuan Tong></a>, <strong>Mengshun Hu</strong>, <a>Zheng Wang</a>
              <br>
              <em>arxiv Preprint</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2306.00973/">arXiv</a>
               / 
              <a href="https://github.com/tongyuantongyu/vs-NNVISR">code</a>
              <br>
            </td>
          </tr>

          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177211">
                <papertitle>CycMuNet+: Cycle-Projected Mutual Learning for Spatial-Temporal Video Super-Resolution</papertitle>
              </a>
              <br>
              <strong>Mengshun Hu</strong>, <a>Kui Jiang</a>, <a>Zheng Wang</a>, <a>Xiang Bai</a>, <a>Ruimin Hu</a>
              <br>
              <em>TPAMI</em>, 2023
              <br>
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10177211">paper</a>
              /
              <a href="https://github.com/Mengshun Hu/CycmuNet+/">code</a>
              <br>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://ojs.aaai.org/index.php/AAAI/article/download/25165/24937">
                <papertitle>Store and fetch immediately: Everything is all you need for space-time video super-resolution</papertitle>
              </a>
              <br>
              <strong>Mengshun Hu</strong>, <a>Kui Jiang</a>, <a>Zhixiang Nie</a>, <a>Jiahuan Zhou</a>, <a>Zheng Wang</a>
              <br>
              <em>AAAI</em>, 2023
              <br>
              <a href="https://ojs.aaai.org/index.php/AAAI/article/download/25165/24937">paper</a>
              <br>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.pdf">
                <papertitle>Spatial-temporal space hand-in-hand: Spatial-temporal video super-resolution via cycle-projected mutual learning</papertitle>
              </a>
              <br>
              <strong>Mengshun Hu</strong>, <a>Kui Jiang</a>, <a>Liang Liao</a>, <a>Jing Xiao</a>, <a>Junjun Jiang</a>, <a>Zheng Wang</a>
              <br>
              <em>CVPR</em>, 2022
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Hu_Spatial-Temporal_Space_Hand-in-Hand_Spatial-Temporal_Video_Super-Resolution_via_Cycle-Projected_Mutual_Learning_CVPR_2022_paper.pdf">paper</a>
              /
              <a href="https://github.com/Mengshun Hu/CycmuNet+/">code</a>
              <br>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547874">
                <papertitle>You only align once: Bidirectional interaction for spatial-temporal video super-resolution</papertitle>
              </a>
              <br>
              <strong>Mengshun Hu</strong>, <a>Kui Jiang</a>, <a>Zhixiang Nie</a>, <a>Zheng Wang</a>
              <br>
              <em>ACM MM</em>, 2022
              <br>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547874">paper</a>
              <br>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547875">
                <papertitle>Progressive spatial-temporal collaborative network for video frame interpolation</papertitle>
              </a>
              <br>
              <strong>Mengshun Hu</strong>, <a>Kui Jiang</a>, <a>Liang Liao</a>, <a>Zhixiang Nie</a>, <a>Jing Xiao</a>, <a>Zheng Wang</a>
              <br>
              <em>ACM MM</em>, 2022
              <br>
              <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3547875">paper</a>
              <br>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://ieeexplore.ieee.org/iel7/6046/4456689/10003662.pdf">
                <papertitle>Progressive Motion Boosting for Video Frame Interpolation</papertitle>
              </a>
              <br>
              <a>Jing Xiao</a>, <a>Kangming Xu</a>, <strong>Mengshun Hu</strong>, <a>Liang Liao</a>, <a>Zheng Wang</a>, <a>Chia-Wen Lin</a>, <a>Mi Wang</a>, <a>Shin'ichi Satoh</a>
              <br>
              <em>TMM</em>, 2022
              <br>
              <a href="https://ieeexplore.ieee.org/iel7/6046/4456689/10003662.pdf">paper</a>
              <br>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://ieeexplore.ieee.org/iel7/76/9788489/09530577.pdf">
                <papertitle>Capturing small, fast-moving objects: Frame interpolation via recurrent motion enhancement</papertitle>
              </a>
              <br>
              <strong>Mengshun Hu</strong>, <a>Jing Xiao</a>, <a>Liang Liao</a>, <a>Zheng Wang</a>, <a>Chia-Wen Lin</a>, <a>Mi Wang</a>, <a>Shin'ichi Satoh</a>
              <br>
              <em>TCSVT</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/iel7/76/9788489/09530577.pdf">paper</a>
              <br>
            </td>
          </tr>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/lar_sr.jpg" alt="lar_sr" width="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://ieeexplore.ieee.org/iel7/76/9788489/09530577.pdf">
                <papertitle>Motion feedback design for video frame interpolation</papertitle>
              </a>
              <br>
              <strong>Mengshun Hu</strong>, <a>Liang Liao</a>, <a>Jing Xiao</a>, <a>Lin Gu</a>, <a>Shin'ichi Satoh</a>
              <br>
              <em>ICASSP</em>, 2020
              <br>
              <a href="https://ieeexplore.ieee.org/iel7/76/9788489/09530577.pdf">paper</a>
              <br>
            </td>
          </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Reviewer Service</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Reviewer Service</heading>
            </td>
          </tr>
        </tbody></table>


        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              2023 Computer Vision and Pattern Recognition (<a href="https://cvpr2023.thecvf.com/">CVPR 2023</a>)
              <br>
              2023 International Conference on Computer Vision (<a href="https://iccv2023.thecvf.com/">ICCV 2023</a>)
            </td>
          </tr>
          
        </tbody></table>


      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Work and Internship</heading>
        </td>
      </tr>
    </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/EE208.jpg" width="160"></td>
        <td width="75%" valign="center">
          T.A. of EE208: 'Introduction to Electrical Engineering C', Fall 2022. 
          <br> (instructors: Prof. <a href='https://mediabrain.sjtu.edu.cn/yazhang/'>Ya Zhang</a> & Prof. Dazhi He)
          <br>
          Cluster Server Administrator of <a href="https://mediabrain.sjtu.edu.cn/">MediaBrain@SJTU</a>, Spring 2023.
        </td>
      </tr>
      
    </tbody></table> -->

    <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=5ayBqtHVZxq64yIbqL91zvhcK44KOAMiyFcLXB3F2nc&cl=ffffff&w=a"></script>
    
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
            </p>
            <p style="text-align:left;font-size:small;"> Updated in June. 2023
            </p>
              <p style="text-align:right;font-size:small;">
                Thanks <a href="https://jonbarron.info/"> Jon Barron</a> for this amazing website template</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
